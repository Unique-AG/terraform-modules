# Prometheus Alert Rules Configuration
# This file contains reusable alert rules for AKS monitoring

# Node Level Alert Rules
prometheus_node_alert_rules = [
  {
    alert      = "KubeNodeUnreachable"
    enabled    = true
    expression = <<EOF
(kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/imminent-node-termination|aws-node-termination-handler/spot-itn"} == 1)
EOF
    for        = "PT15M"
    severity   = 3
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    annotations = {
      description = "{{ $labels.node }} in {{ $labels.cluster }} is unreachable."
    }
    labels = {
      team       = "prod"
      alert_name = "KubeNodeUnreachable"
    }
  },
  {
    alert      = "KubeNodeReadinessFlapping"
    enabled    = true
    expression = "sum(changes(kube_node_status_condition{status=\"true\",condition=\"Ready\"}[15m])) by (cluster, node) > 2"
    for        = "PT15M"
    severity   = 3
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    annotations = {
      description = "Node readiness is flapping."
    }
    labels = {
      team       = "prod"
      alert_name = "KubeNodeReadinessFlapping"
    }
  }
]

# Cluster Level Alert Rules
prometheus_cluster_alert_rules = [
  {
    alert = "KubeCPUQuotaOvercommit"
    annotations = {
      description = "Cluster {{ $labels.cluster }} has overcommitted CPU resource requests for Namespaces."
    }
    enabled    = true
    expression = "sum(min without(resource) (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\", resource=~\"(cpu|requests.cpu)\"})) / sum(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"}) > 1.5"
    for        = "PT5M"
    labels = {
      severity = "warning"
    }
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    severity = 3
  },
  {
    alert = "KubeMemoryQuotaOvercommit"
    annotations = {
      description = "Cluster {{ $labels.cluster }} has overcommitted memory resource requests for Namespaces."
    }
    enabled    = true
    expression = "sum(min without(resource) (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\", resource=~\"(memory|requests.memory)\"})) / sum(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"}) > 1.5"
    for        = "PT5M"
    labels     = {}
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    severity = 3
  },
  {
    alert = "KubeContainerOOMKilledCount"
    annotations = {
      description = "Number of OOM killed containers is greater than 0."
    }
    enabled    = true
    expression = "sum by (cluster,container,controller,namespace) (kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"} * on(cluster,namespace,pod) group_left(controller) label_replace(kube_pod_owner, \"controller\", \"$1\", \"owner_name\", \".*\")) > 0"
    for        = "PT5M"
    labels     = {}
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    severity = 4
  },
  {
    alert = "KubeClientErrors"
    annotations = {
      description = "Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors."
    }
    enabled    = true
    expression = "(sum(rate(rest_client_requests_total{code=~\"5..\"}[5m])) by (cluster, instance, job, namespace) / sum(rate(rest_client_requests_total[5m])) by (cluster, instance, job, namespace)) > 0.01"
    for        = "PT15M"
    labels     = {}
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    severity = 3
  }
]

# Pod Level Alert Rules
prometheus_pod_alert_rules = [
  {
    alert      = "KubePVUsageHigh"
    enabled    = true
    expression = <<EOF
avg by (namespace, controller, container, cluster) (
  (kubelet_volume_stats_used_bytes{job="kubelet"} / on(namespace, cluster, pod, container) group_left
  kubelet_volume_stats_capacity_bytes{job="kubelet"}) * on(namespace, pod, cluster) group_left(controller)
  label_replace(kube_pod_owner, "controller", "$1", "owner_name", "(.*)")
) > 0.8
EOF
    for        = "PT15M"
    severity   = 3
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    annotations = {
      description = "Average PV usage on pod {{ $labels.pod }} in container {{ $labels.container }} is greater than 80%."
    }
    labels = {
      alert_name = "KubePVUsageHigh"
    }
  },
  {
    alert      = "KubePodCrashLooping"
    enabled    = true
    expression = <<EOF
max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
EOF
    for        = "PT15M"
    severity   = 4
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT10M"
    }
    annotations = {
      description = "{{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) in {{ $labels.cluster}} is restarting {{ printf \"%.2f\" $value }} / second."
    }
    labels = {
      alert_name = "KubePodCrashLooping"
    }
  },
  {
    alert      = "KubeDeploymentReplicasMismatch"
    enabled    = true
    expression = <<EOF
(
  kube_deployment_spec_replicas{job="kube-state-metrics"} > kube_deployment_status_replicas_available{job="kube-state-metrics"}
  and (changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0)
)
EOF
    for        = "PT15M"
    severity   = 4
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT15M"
    }
    annotations = {
      description = "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} in {{ $labels.cluster}} replica mismatch."
    }
    labels = {
      alert_name = "KubeDeploymentReplicasMismatch"
    }
  },
  {
    alert      = "KubePodReadyStateLow"
    enabled    = true
    expression = <<EOF
sum by (cluster,namespace,deployment)
(kube_deployment_status_replicas_ready) / sum by
(cluster,namespace,deployment)(kube_deployment_spec_replicas) < .8 or sum
by (cluster,namespace,deployment)(kube_daemonset_status_number_ready) /
sum by (cluster,namespace,deployment)(kube_daemonset_status_desired_number_scheduled) < .8
EOF
    for        = "PT5M"
    severity   = 4
    alert_resolution = {
      auto_resolved   = true
      time_to_resolve = "PT15M"
    }
    annotations = {
      description = "Ready state of pods is less than 80%."
    }
    labels = {
      alert_name = "KubePodReadyStateLow"
    }
  }
]

# Alert Configuration
alert_configuration = {
  email_receiver = {
    email_address = "admin@example.com"
    name          = "aks-admin-alerts"
  }
  action_group = {
    short_name = "aks-alerts"
    location   = "germanywestcentral"
  }
} 